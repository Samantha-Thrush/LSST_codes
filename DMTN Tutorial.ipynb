{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a basic tutorial from  https://dmtn-023.lsst.io .  You will notice that some of the commands are different from the site given above; this is due to the fact that some of those commands on the site are obsolete.  \n",
    "\n",
    "Here we setup the stack using the w_2017_18 tag.\n",
    "Note: this should all be done within an NCSA terminal session (it will be easiest that way). RUN THIS EVERY TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    ". /software/lsstsw/stack/loadLSST.bash\n",
    "setup lsst_distrib -t w_2017_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a folder for the `ci_hsc` data (if the path doesn't exist, make it; anyPath can truly be any path that you want) and then change directories to your new folder. Put git_lfs on your path so that you can use it.  Obviously, change $username to your NCSA username. RUN THIS EVERY TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /scratch/$username/anyPath/\n",
    "export PATH=/ssd/lsstsw/stack/Linux64/git_lfs/2.0.2/bin/:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must have LFS up and working so you have to do the following three code cells (you only have to do this once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add these 4 lines to the ~/.gitconfig file:\n",
    "Cache anonymous access to DM Git LFS S3 servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[credential \"https://lsst-sqre-prod-git-lfs.s3-us-west-2.amazonaws.com\"]\n",
    "  helper = store\n",
    "[credential \"https://s3.lsst.codes\"]\n",
    "  helper = store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add these 2 lines to ~/.git-credentials (if need be, create one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://:@lsst-sqre-prod-git-lfs.s3-us-west-2.amazonaws.com\n",
    "https://:@s3.lsst.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we copy the ci_hsc data from github; you only need to do this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/lsst/ci_hsc.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ci_hsc automatically;  see README on https://github.com/lsst/ci_hsc if you have questions.  The `scons` command will take a couple hours to go through, so while it is working away, open another terminal and let's try to recreate what it is doing by hand so that we get an idea of the codes being used.\n",
    "\n",
    "*NOTE*: `scons` does not use `coaddDriver.py` or `multiBandDriver.py` currently (thanks Hsin-Fang!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ci_hsc/\n",
    "setup -k -r .\n",
    "scons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open a new window to work in while scons is busy, remember to rerun the cd ci_hsc and setup or else this will not work.  Additionally, you should also run the . /software/ and setup lsst command at the top of the page; otherwise this will throw an error. Also, do not forget to cd into `ci_hsc` and run the `setup -k -r .`.  If you don't, you'll throw an error.\n",
    "\n",
    "Here we are preparing a new data repository in the directory called \"DATA2\".  Unlike normal files, the files within DATA2 should only be accessed or modified by the butler (lsst.dat.persistence.Butler).  The `echo` command simply tells the butler which mapper our repo is using.  `ingestImages.py` will put the raw image symlinks into our data repo and create a registry of all of the raw images in our repo.\n",
    "\n",
    "Once we have ingested the raw images, we then create a symlink to our calibration frames, and then we create an additional symlink to our desired reference catalog.  In the dmtn-023 link above, this was done using eups; not exactly sure why we differ in this case from the tutorial. \n",
    "\n",
    "*NOTE*: The default reference catalog for HSC was changed from the astrometry_net style to the new HTM style in [DM-9438](https://jira.lsstcorp.org/browse/DM-9438). The default for other cameras are still the astrometry_net style as of today. Supposedly if we tweak the config properly, we can still use the astrometry_net reference catalog for HSC. (Thanks Hsin-Fang!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir DATA2\n",
    "echo \"lsst.obs.hsc.HscMapper\" > DATA2/_mapper\n",
    "ingestImages.py DATA2 $CI_HSC_DIR/raw/*.fits --mode=link\n",
    "\n",
    "cd DATA2\n",
    "ln -s $CI_HSC_DIR/CALIB .\n",
    "mkdir ref_cats\n",
    "ln -s $CI_HSC_DIR/ps1_pv3_3pi_20170110 ref_cats/ps1_pv3_3pi_20170110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing `singleFrameDriver.py`, we instead do most of the same work with `processCcd.py`.\n",
    "\n",
    "THREE WAYS OF PROCESSING CCD: \n",
    "- One visit and one ccd, \n",
    "- one visit with many ccd's, and \n",
    "- many visits with many ccd's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "processCcd.py . --rerun example --id visit=903986 ccd=16\n",
    "processCcd.py . --rerun example --id visit=903334 ccd=16^23\n",
    "processCcd.py . --rerun example --id visit=903336 ccd=17^24 \n",
    "    --id visit=903342 ccd=4^10 --id visit=903344 ccd=5^11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are making the sky maps, you are essentially making a tract or patch in the sky based on the visit ID's that you specify.  If you want to make a sky map of the whole sky, you simply use the command `makeSkyMap.py`.\n",
    "\n",
    "(I'm not sure if we got the first command to work, but if you run the next line, you should be fine).\n",
    "\n",
    "The use of `example:exampleDistSkyMap` allows me to chain together the input and output folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "makeDiscreteSkyMap.py . --rerun example:exampleDistSkyMap \n",
    "    --id visit=903334 ccd=16^23 --id visit=903986 ccd=16 \n",
    "    --config skyMap.projection=\"TAN\" \n",
    "makeSkyMap.py . --rerun example -C $CI_HSC_DIR/skymap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three steps are usually done by the coaddDriver.py when scons is running; this simply builds a coadd patch-by-patch.  Makes lots of different data products (`deepCoadd_tempExp`, `deepCoadd_calexp`, `deepCoadd`, and `deepCoadd_det`) that can be viewed with `butler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "makeCoaddTempExp.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I -c doApplyUberCal=False --selectId visit=903986 ccd=16 --selectId visit=903334 ccd=16^23 --selectId visit=903336 ccd=17^24 --selectId visit=903342 ccd=4^10 --selectId visit=903344 ccd=5^11\n",
    "assembleCoadd.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I --selectId visit=903986 ccd=16 --selectId visit=903334 ccd=16^23 --selectId visit=903336 ccd=17^24 --selectId visit=903342 ccd=4^10 --selectId visit=903344 ccd=5^11 --clobber-config (if you do this right the first time, you shouldn't have to clobber)\n",
    "detectCoaddSources.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four steps are also usually done by multiBandDriver.py in scons:\n",
    "- First we merge the detections across bands in a patch, which creates the data product `deepCoadd_mergeDet`\n",
    "- Next, we deblend and measure objects independently in every band, which creates the data product `deepCoadd_meas`\n",
    "- Then we compare measurements across bands using a reference band for each object to create the data product `deepCoadd_ref`.\n",
    "- Finally, we measure again in everyband while we take the positions and shapes as constant using the values in the reference band to create `deepCoadd_forced_src` which has flux measurements with the best estimates of colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mergeCoaddDetections.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I^HSC-R\n",
    "measureCoaddSources.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I\n",
    "mergeCoaddMeasurements.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I^HSC-R\n",
    "forcedPhotCoadd.py . --rerun example --id patch=5,4 tract=0 filter=HSC-I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do forced photometry on exposure images with the coadd reference catalog.  Unfortunately, this doesn't yet have a way to deblend sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "forcedPhotCcd.py . --rerun example --id visit=903986 ccd=16 tract=0 -C $CI_HSC_DIR/forcedPhotCcdConfig.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Butler\n",
    "\n",
    "It is all nice and well that we have made this data above, but without accessing it, it is useless.  So, in order to access it, we will first need to run the first code cell in this notebook. **IF YOU DON'T DO THIS, THE CODE BELOW WILL NOT WORK.**  \n",
    "\n",
    "Once this is done, if you are in a bash shell you can then start a python inline session by simply entering `python`.  Alternately, if you are in a notebook that is connected to the NCSA server, you can just proceed as shown below.\n",
    "\n",
    "First you must create a Butler constructor (making sure you are in the DATA directory that you want to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lsst.daf.persistence import Butler\n",
    "butler = Butler(\"rerun/example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, you may extract any data products that you've made.  Below are some examples taken directly from https://dmtn-023.lsst.io.  You may change them as you see fit.\n",
    "\n",
    "*NOTE*: The default of immediate has been changed to true earlier this year (DM-8096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calexp = butler.get(\"calexp\", visit=903334, ccd=16, immediate=True)\n",
    "src = butler.get(\"src\", visit=903334, ccd=16, immediate=True)\n",
    "skyMap = butler.get(\"deepCoadd_skyMap\", immediate=True)\n",
    "coadd = butler.get(\"deepCoadd_calexp\", tract=0, patch=\"1,1\", filter=\"HSC-I\", immediate=True)\n",
    "meas = butler.get(\"deepCoadd_meas\", tract=0, patch=\"1,1\", filter=\"HSC-I\", immediate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for a bit of clarity: `immediate` is set to `true` so that Butler will read and return objects immediately.  If immediate is False or simply not set, then you'll have to go through an I/O proxy (really annoying and sometimes confusing). \n",
    "\n",
    "Please note that using `butler.get` will not necessarily give output that is human-readable.  Instead, `butler.get` will give output that can be given to other codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ds9: image viewing\n",
    "\n",
    "In order to do that, you must use ds9.  A good way to do this is to follow the steps taken here: https://community.lsst.org/t/using-an-lsst-dev-stack-w-local-ipython-ds9-tutorial/592\n",
    "\n",
    "Also, remember: in order to keep your sanity, do this either in a Linux environment (your VM is just fine) or on a Mac; this is NOT easy to do on a Windows machine.\n",
    "\n",
    "A couple words of warning, however:\n",
    "- When you create ~/.ssh/config, do not enclose ANYTHING <>. Instead, simply put the desired values in for your username, XXXX, YYYY, and ZZZZ\n",
    "- REMEMBER TO EXPORT THE XPA PORTS EACH TIME BEFORE YOU LAUNCH DS9\n",
    "- Please remember to do the long ssh command for the first call of the day; otherwise the localhost call on Firefox will not work\n",
    "- YOU MUST MANUALLY LAUNCH DS9 EACH TIME BEFORE YOU TRY TO SSH INTO LSST-DEV AND DO NOT EXIT OUT OF DS9 UNTIL YOU ARE DONE WITH YOUR SSH SESSION\n",
    "- Once you launch ds9, _always_ check in File > XPA > Information to make sure that the second number for XPA_METHOD matches with XXXX that you entered into your export method\n",
    "- After you ssh into lsst-dev, DO NOT use the method on the website above to setup the stack; instead, do the following:\n",
    "```\n",
    ". /software/lsstsw/stack/loadLSST.bash\n",
    "setup lsst_distrib -t w_2017_18\n",
    "```\n",
    "- Do not forget to export the XPA_PORT again!\n",
    "- Use the first method for launching the Ipython notebook; you shouldn't need a continuous session\n",
    "- Always try out their test case to make sure everything is working properly: \n",
    "\n",
    "\n",
    "```\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.display as afwDisplay\n",
    "import numpy as np\n",
    "\n",
    "data = np.zeros((10,10), dtype=np.float32)\n",
    "img = afwImage.ImageF(data)\n",
    "afwDisplay.mtv(img,frame=0)\n",
    "```\n",
    "\n",
    "- Here is another good test case:\n",
    "\n",
    "```import lsst.afw.display as afwDisplay\n",
    "import lsst.daf.persistence as dafPersist\n",
    "butler = dafPersist.Butler(\"/datasets/hsc/repo/rerun/private/hchiang2/RC/DM-10129\")\n",
    "exp = butler.get(\"raw\", visit=350, ccd=3)\n",
    "afwDisplay.getDisplay().mtv(exp)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DMTN Tutorial, Mark-II: From \n",
    "## https://dmtn-023.lsst.io/\n",
    "\n",
    "Now, this tutorial is going to be done for the explicit reason of working on and understanding the maker functions.  This will follow along with DMTN much more closely than above.  Send good vibes people.  And maybe a bottle of Crown and a case of vanilla Coke.\n",
    "\n",
    "Note: as you are following along, DON'T use the eups command or the setup below it; instead use the ref_cats and ln above.  Below is a rundown of a translation of the DMTN tutorial.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    ". /software/lsstsw/stack/loadLSST.bash\n",
    "setup lsst_distrib -t w_2017_18\n",
    "cd /scratch/$username/anyPath/\n",
    "export PATH=/ssd/lsstsw/stack/Linux64/git_lfs/2.0.2/bin/:$PATH\n",
    "cd ci_hsc/\n",
    "setup -k -r .\n",
    "\n",
    "mkdir DATA3\n",
    "echo \"lsst.obs.hsc.HscMapper\" > DATA2/_mapper\n",
    "ingestImages.py DATA2 $CI_HSC_DIR/raw/*.fits --mode=link\n",
    "\n",
    "cd DATA3\n",
    "ln -s $CI_HSC_DIR/CALIB .\n",
    "mkdir ref_cats\n",
    "ln -s $CI_HSC_DIR/ps1_pv3_3pi_20170110 ref_cats/ps1_pv3_3pi_20170110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do singleFramDriver, which processes the visits.  This can be done one visit at a time, or many at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "singleFrameDriver.py . --rerun example1 --id visit=903334 --cores=4\n",
    "singleFrameDriver.py . --rerun example1 --cores=4 \\\n",
    "  --id visit=903334..903338:2 --id visit=903342..903346:2 \\\n",
    "  --id visit=903986..903990:2 --id visit=904010^904014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the sky maps as above.  Still not sure if makeDiscreteSkyMap is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "makeDiscreteSkyMap.py . --rerun example1:example2 \\\n",
    "  --id visit=903334..903338:2 --id visit=903342..903346:2 \\\n",
    "  --id visit=903986..903990:2 --id visit=904010^904014 \\\n",
    "  --config skyMap.projection=\"TAN\"\n",
    "makeSkyMap.py . --rerun example1 -C $CI_HSC_DIR/skymap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the coadds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## not sure if these work\n",
    "coaddDriver.py DATA --rerun example1 \\\n",
    "  --selectId visit=903334..903338:2 --selectId visit=903342..903346:2 \\\n",
    "  --id tract=0 patch=1,1 filter=HSC-R --cores=4 \\\n",
    "  --config assembleCoadd.doApplyUberCal=False \\\n",
    "  makeCoaddTempExp.doApplyUberCal=False\n",
    "  \n",
    "coaddDriver.py DATA --rerun example1 \\\n",
    "  --selectId visit=903986..903990:2 --selectId visit=904010^904014 \\\n",
    "  --id tract=0 patch=1,1 filter=HSC-I --cores=4 \\\n",
    "  --config assembleCoadd.doApplyUberCal=False \\\n",
    "  makeCoaddTempExp.doApplyUberCal=False\n",
    "\n",
    "coaddDriver.py DATA --rerun example1 \\\n",
    "  --selectId visit=903334..903338:2 --selectId visit=903342..903346:2 \\\n",
    "  --id tract=0 patch=0,0^0,1^0,2^1,0^1,2^2,0^2,1^2,2 filter=HSC-R \\\n",
    "  --cores=4\n",
    "  --config assembleCoadd.doApplyUberCal=False \\\n",
    "  makeCoaddTempExp.doApplyUberCal=False\n",
    "  \n",
    "coaddDriver.py DATA --rerun example1 \\\n",
    "  --selectId visit=903986..903990:2 --selectId visit=904010^904014 \\\n",
    "  --id tract=0 patch=0,0^0,1^0,2^1,0^1,2^2,0^2,1^2,2 filter=HSC-I \\\n",
    "  --cores=4\n",
    "  --config assembleCoadd.doApplyUberCal=False \\\n",
    "  makeCoaddTempExp.doApplyUberCal=False\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make the color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiBandDriver.py . --rerun example1:example3 \\\n",
    "  --id tract=0 patch=1,1 filter=HSC-R^HSC-I \\\n",
    "  --cores=2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
